{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00db323d-2c52-4bca-ab04-e98d0d76f464",
   "metadata": {},
   "source": [
    "# Наумкин Владимир, С01-119."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12460ca5-e159-4725-a659-6e6b7638112b",
   "metadata": {},
   "source": [
    "## Задача 1. Распознавание именованных сущностей на основе fasttext."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a4ee5-fccc-4f4c-bfab-549fa92b90c5",
   "metadata": {},
   "source": [
    "### Подключим библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d2270c-3698-4b6c-be9a-3dd2bb9b471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext # pip install fasttext-wheel\n",
    "import fasttext.util\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nerus import load_nerus\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364890d-9ab7-4083-97d6-1f91e2f9f082",
   "metadata": {},
   "source": [
    "### Уберём предупреждения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e3a645-4d96-4fc3-a26e-7011a1730c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff857844-0e2a-4125-99d0-6a4901834f23",
   "metadata": {},
   "source": [
    "### Зададим устройство исполнения кода (вычисления провожу на своём ПК)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0aeb4e-9e28-4bcd-90ee-55a317a0c40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c1cce-36ea-46a3-8b7c-39ca2043f228",
   "metadata": {},
   "source": [
    "### Код для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f0543b-073e-46fa-9f00-e405994749be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    preds = model(x_batch.to(model.device))\n",
    "    loss = loss_fn(preds.transpose(1, 2).to(model.device), y_batch.to(model.device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7149ed-fa57-4866-9ee8-86bdfef098bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_loader, model, loss_fn, optimizer, callback=None):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        batch_loss = train_on_batch(model, x, y, optimizer, loss_fn)\n",
    "        data_loader.set_postfix({'current training loss': batch_loss})\n",
    "        if callback != None:\n",
    "            callback(model, batch_loss)\n",
    "        total_loss += batch_loss * len(x)\n",
    "        count += len(x)\n",
    "    return total_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd600b2f-de0b-4332-b32f-ab9dab63a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, tag2index, token2index, batch_size=64, do_shuffle=True):\n",
    "    tokens, tags = data\n",
    "    PAD_TOK = token2index['[PAD]']\n",
    "    PAD_TAG = tag2index['[PAD]']\n",
    "    sample_size = len(tokens)\n",
    "    indices = np.arange(sample_size)\n",
    "    if do_shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    shuffled_tokens = [tokens[idx] for idx in indices]\n",
    "    shuffled_tags = [tags[idx] for idx in indices]\n",
    "    num_batches = (sample_size // batch_size) + (1 if sample_size % batch_size else 0)\n",
    "    for batch_index in range(num_batches):\n",
    "        end_index = min((batch_index + 1) * batch_size, sample_size)\n",
    "        batch_tokens = shuffled_tokens[batch_index * batch_size:end_index]\n",
    "        batch_tags = shuffled_tags[batch_index * batch_size:end_index]\n",
    "        max_len = max(len(sentence) for sentence in batch_tokens)\n",
    "        batch_x = np.full((end_index - batch_index * batch_size, max_len), PAD_TOK)\n",
    "        batch_y = np.full((end_index - batch_index * batch_size, max_len), PAD_TAG)\n",
    "        for j in range(end_index - batch_index * batch_size):\n",
    "            token_ids = [token2index.get(token, token2index['O']) for token in batch_tokens[j]]\n",
    "            tag_ids = [tag2index.get(tag, tag2index['O']) for tag in batch_tags[j]]\n",
    "            batch_x[j, :len(token_ids)] = token_ids\n",
    "            batch_y[j, :len(tag_ids)] = tag_ids\n",
    "        yield torch.LongTensor(batch_x), torch.LongTensor(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9b4c88-0c3b-44c4-ad78-be32a723a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(num_epochs, batch_size, model, data, tag_to_index, token_to_index, loss_fn, optimizer, callback):\n",
    "    epochs = tqdm(range(num_epochs))\n",
    "    for epoch in epochs:\n",
    "        current_optimizer = optimizer\n",
    "        batch_count = len(data[0]) // batch_size + (len(data[0]) % batch_size > 0)\n",
    "        batch_gen = tqdm(create_batches(data, tag_to_index, token_to_index, batch_size=batch_size, do_shuffle=True),\n",
    "                         leave=False, total=batch_count)\n",
    "        epoch_loss = train_epoch(data_loader=batch_gen,\n",
    "                                            model=model,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=current_optimizer,\n",
    "                                            callback=callback)\n",
    "        epochs.set_postfix({'average loss for epoch': epoch_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e57f9c-c4a9-41af-89bf-5f64f6c41494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback():\n",
    "    def __init__(self, writer, dataset, tag2idx, token2idx, loss_function, delimeter=100, batch_size=64):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "        self.tag2idx = tag2idx\n",
    "        self.token2idx = token2idx\n",
    "        self.dataset = dataset\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar('LOSS/train', loss, self.step)\n",
    "        if self.step % self.delimeter == 1:\n",
    "            real, pred = [], []\n",
    "            number_of_batch = len(self.dataset[0]) // self.batch_size + (len(self.dataset[0])%self.batch_size > 0)\n",
    "            generator = create_batches(self.dataset, self.tag2idx, self.token2idx, batch_size=self.batch_size)\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            for it, (batch_of_x, batch_of_y) in enumerate(generator):\n",
    "                batch_of_x = batch_of_x.to(model.device)\n",
    "                batch_of_y = batch_of_y.to(model.device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(batch_of_x.to(model.device))\n",
    "                    test_loss += self.loss_function(output.transpose(1,2), batch_of_y).cpu().item()*len(batch_of_x)\n",
    "                pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "                real.extend(batch_of_y.cpu().numpy().tolist())\n",
    "            test_loss /= len(self.dataset[0])\n",
    "            self.writer.add_scalar('LOSS/test', test_loss, self.step)\n",
    "            pred4report = []\n",
    "            real4report = []\n",
    "            for (sent_real, sent_pred) in zip(real, pred):\n",
    "                realWOpad = []\n",
    "                predWOpad = []\n",
    "                for (i, idx) in enumerate(sent_real):\n",
    "                    if idx != self.tag2idx['[PAD]']:\n",
    "                        realWOpad.append(index_to_tag[idx])\n",
    "                        predWOpad.append(index_to_tag[sent_pred[i]])\n",
    "                real4report.append(realWOpad)\n",
    "                pred4report.append(predWOpad)\n",
    "            flat_real = [item for sublist in real4report for item in sublist]\n",
    "            flat_pred = [item for sublist in pred4report for item in sublist]\n",
    "            self.writer.add_text('REPORT/test', str(classification_report(flat_real, flat_pred)), self.step)\n",
    "            nice_sentence = \"По словам Владимира Наумкина, самым лучшим учебным заведением России является МФТИ.\"\n",
    "            sample = sample_model(model)\n",
    "            self.writer.add_text('TEXT/test', nice_sentence + '\\n' + sample, self.step)\n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d3f96-3f40-4106-8355-cf10f20948f8",
   "metadata": {},
   "source": [
    "### Датасет NERUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de475f5e-797f-48cf-ac68-ac4b7086474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 92481\n"
     ]
    }
   ],
   "source": [
    "docs = load_nerus('nerus_lenta.conllu.gz')\n",
    "tokens = []\n",
    "tags = []\n",
    "\n",
    "n_docs = 7777\n",
    "for _ in range(n_docs):\n",
    "    doc = next(docs)\n",
    "    for sent in doc.sents:\n",
    "        sent_tokens = []\n",
    "        sent_tags = []\n",
    "        for word in sent.tokens:\n",
    "            sent_tokens.append(word.text)\n",
    "            sent_tags.append(word.tag)\n",
    "        tokens.append(sent_tokens)\n",
    "        tags.append(sent_tags)\n",
    "\n",
    "print(f\"Number of sentences: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb85403-5713-45e3-b979-a15bbdc7507d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size = 73984; Test set size = 18497;\n",
      "Total sentences = 92481 = 92481\n"
     ]
    }
   ],
   "source": [
    "num_sentences = len(tokens)\n",
    "training_tokens, testing_tokens, training_tags, testing_tags = train_test_split(tokens, tags, test_size=0.2, random_state=7)\n",
    "train_data = [training_tokens, training_tags]\n",
    "test_data = [testing_tokens, testing_tags]\n",
    "print(f\"Training set size = {len(training_tokens)}; Test set size = {len(testing_tokens)};\")\n",
    "print(f\"Total sentences = {len(training_tokens) + len(testing_tokens)} = {num_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a18b2be-3039-46e6-be29-755dd18e0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 tags: ['B-LOC', 'B-ORG', 'B-PER', 'I-LOC', 'I-ORG', 'I-PER', 'O', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "tags = train_data[1]\n",
    "tags_set = set(['[PAD]'])\n",
    "for sent_tags in tags:\n",
    "    for tag in sent_tags:\n",
    "        tags_set.add(tag)\n",
    "tags_list = sorted(tags_set)\n",
    "print(f\"{len(tags_list)} tags: {tags_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68959de3-b8f0-41cd-9bdd-eb7caa94413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-PER': 1.3253905935110573,\n",
       " 'I-ORG': 1.7462134896204982,\n",
       " 'O': 90.15223667593203,\n",
       " 'B-LOC': 2.3242291880013974,\n",
       " 'B-ORG': 2.156810643132033,\n",
       " 'I-LOC': 0.3637975870233087,\n",
       " 'B-PER': 1.9313218227796702}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tags = [item for sublist in train_data[1] for item in sublist]\n",
    "tags_freq = dict((x, flat_tags.count(x) * 100 / len(flat_tags)) for x in set(flat_tags) if flat_tags.count(x) > 0)\n",
    "tags_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957832a2-e1fa-46ae-b41d-0f377beb7e5e",
   "metadata": {},
   "source": [
    "Как мы видим, большинство слов не являются именованными сущностями (тег 'O' = other). Также есть 3 типа именованных сущностей: персоны, организации и локации; каждая из которых подразделяется на начало (beginning) и внутреннюю часть (inside)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfdf8b1-7447-4076-bfef-0b743b67245c",
   "metadata": {},
   "source": [
    "### Модель fasttext и словари"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b5be3f-efaa-4415-904a-a46686ee97c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Не хватило оперативки на компе\n",
    "# https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
    "ft = fasttext.load_model('cc.ru.300.bin')\n",
    "print(ft.get_dimension())\n",
    "fasttext.util.reduce_model(ft, 100)\n",
    "print(ft.get_dimension())\n",
    "\"\"\"\n",
    "# https://huggingface.co/kernela/fasttext-ru-vectors-dim-100/blob/main/ru-vectors-dim-100.bin\n",
    "ft = fasttext.load_model('ru-vectors-dim-100.bin')\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca46c94-5a34-466f-bf9b-bb5a9ea9c88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e7fc18f15f426fa9a46069b7b698c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_to_index = {}\n",
    "index_to_token = {}\n",
    "embedding_matrix = []\n",
    "\n",
    "for index, word in enumerate(tqdm(ft.get_words(on_unicode_error='replace'))):\n",
    "    vector = ft.get_word_vector(word)\n",
    "    if word not in token_to_index:\n",
    "        token_to_index[word] = index\n",
    "        index_to_token[index] = word\n",
    "        embedding_matrix.append(vector)\n",
    "\n",
    "for special_token in ['[PAD]', '[UNK]']:\n",
    "    current_index = len(token_to_index)\n",
    "    token_to_index[special_token] = current_index\n",
    "    index_to_token[current_index] = special_token\n",
    "    embedding_matrix.append(np.zeros_like(embedding_matrix[0]))\n",
    "\n",
    "embedding_matrix = np.array(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe125a3-8516-49c9-91fe-1739610eac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_to_index = {tag: index for index, tag in enumerate(tags_list)}\n",
    "index_to_tag = {index: tag for index, tag in enumerate(tags_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f65bb6-49ff-42a2-b262-bb2887e19f1d",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd1f90d-2b48-4d1d-80f3-2ebb0e5d5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 number_of_classes,\n",
    "                 embedding_dimension=20,\n",
    "                 hidden_layer_size=20,\n",
    "                 layer_count=3,\n",
    "                 dropout_rate=0,\n",
    "                 use_batch_norm=False,\n",
    "                 is_bidirectional=False):\n",
    "        super(RecurrentNeuralNetwork, self).__init__()\n",
    "        self.num_directions = 2 if is_bidirectional else 1\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.token_embeddings = torch.nn.Embedding(vocabulary_size, embedding_dimension)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dimension,\n",
    "                                  hidden_layer_size,\n",
    "                                  layer_count,\n",
    "                                  dropout=dropout_rate,\n",
    "                                  batch_first=True,\n",
    "                                  bidirectional=is_bidirectional)\n",
    "        self.output_layer = torch.nn.Linear(hidden_layer_size * self.num_directions, number_of_classes)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(hidden_layer_size * self.num_directions) if use_batch_norm else None\n",
    "    def forward(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        lstm_output, (hidden_state, cell_state) = self.lstm(embedded_tokens)\n",
    "        if self.use_batch_norm:\n",
    "            lstm_output = self.batch_norm(lstm_output.transpose(1, 2)).transpose(1, 2)\n",
    "        return self.output_layer(lstm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d896e-46c1-4703-9058-a8a8de7f154d",
   "metadata": {},
   "source": [
    "Создаём модель с предобученным fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65814277-7f44-4bc5-b6bd-a631368ad3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'vocabulary_size': len(token_to_index),\n",
    "    'number_of_classes': len(tags_list),\n",
    "    'embedding_dimension': 100,\n",
    "    'hidden_layer_size': 100,\n",
    "    'layer_count': 1,\n",
    "    'use_batch_norm': True,\n",
    "    'is_bidirectional': False\n",
    "}\n",
    "\n",
    "neural_network = RecurrentNeuralNetwork(**model_config)\n",
    "neural_network.token_embeddings.weight.data.copy_(torch.tensor(embedding_matrix))\n",
    "for param in neural_network.token_embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "neural_network = neural_network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e95b9-701b-4a55-892c-a79dcd3b05fc",
   "metadata": {},
   "source": [
    "### Функции проверки качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec83e829-8b7b-42a9-bf6e-de8e10da0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(neural_network, test_data):\n",
    "    test_data_batches = create_batches(test_data, tag_to_index, token_to_index, batch_size=64)\n",
    "    predicted_tags = []\n",
    "    actual_tags = []\n",
    "    neural_network.eval() \n",
    "    for iteration, (x_batch, y_batch) in enumerate(test_data_batches):\n",
    "        x_batch = x_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            model_output = neural_network(x_batch)\n",
    "        predicted_tags.extend(torch.argmax(model_output, dim=-1).cpu().numpy().tolist())\n",
    "        actual_tags.extend(y_batch.cpu().numpy().tolist())\n",
    "    processed_predictions = []\n",
    "    processed_actuals = []\n",
    "    for real_tags_sequence, predicted_tags_sequence in zip(actual_tags, predicted_tags):\n",
    "        filtered_actual_tags = []\n",
    "        filtered_predicted_tags = []\n",
    "        for idx, tag_index in enumerate(real_tags_sequence):\n",
    "            if tag_index != tag_to_index['[PAD]']:  # Не учитываем паддинг\n",
    "                filtered_actual_tags.append(index_to_tag[tag_index])\n",
    "                filtered_predicted_tags.append(index_to_tag[predicted_tags_sequence[idx]])\n",
    "        processed_actuals.append(filtered_actual_tags)\n",
    "        processed_predictions.append(filtered_predicted_tags)\n",
    "    flat_actual_tags = [tag for sublist in processed_actuals for tag in sublist]\n",
    "    flat_predicted_tags = [tag for sublist in processed_predictions for tag in sublist]\n",
    "    print(classification_report(flat_actual_tags, flat_predicted_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90fa6620-520d-48b0-8f71-a6337def5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(model, sentence = ['По', 'словам', 'Владимира', 'Наумкина', ',',\n",
    "                                    'самым', 'лучшим', 'учебным', 'заведением', 'России',\n",
    "                                    'является', 'МФТИ', '.']):\n",
    "    # Преобразуем токены в индексы\n",
    "    token_indices = [token_to_index.get(token, token_to_index['[UNK]']) for token in sentence]\n",
    "    #token_indices = [token_to_index[token] for token in sentence] # Изначально было так (во время обучения),\n",
    "                                                                   # хорошо, что не нарвался на ошибку\n",
    "                                                                   # заметил только при финальном тесте (см. выводы)\n",
    "    # Преобразуем список индексов в тензор\n",
    "    input_tensor = torch.tensor(token_indices, dtype=torch.long).unsqueeze(0).to(model.device)  # Добавляем размерность для батча\n",
    "    # Получаем предсказания от модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # Не нужно вычислять градиенты\n",
    "        output = model(input_tensor)\n",
    "    # Получаем индексы с максимальным значением для каждого токена\n",
    "    predicted_indices = output.argmax(dim=2).squeeze().cpu().numpy()  # Убираем размерность батча\n",
    "    # Преобразуем индексы в теги\n",
    "    predicted_tags = [index_to_tag[index] for index in predicted_indices]\n",
    "    # Объединяем теги в одну строку\n",
    "    tags_string = ' '.join(predicted_tags)\n",
    "    return tags_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74812be-b31e-4c9f-b05a-2c3fc57ec28a",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d364ac8f-1f4c-413f-8f79-3d0105b512cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=tag_to_index['[PAD]'])\n",
    "optimizer = torch.optim.Adam(neural_network.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6b39b-98d8-4383-ad22-b896be134495",
   "metadata": {},
   "source": [
    "Качество до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876ab892-b4c8-4cd4-81a9-a95d166b92b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00      7776\n",
      "       B-ORG       0.02      1.00      0.04      7388\n",
      "       B-PER       0.00      0.00      0.00      6396\n",
      "       I-LOC       0.00      0.00      0.00      1254\n",
      "       I-ORG       0.00      0.00      0.00      5813\n",
      "       I-PER       0.00      0.00      0.00      4340\n",
      "           O       0.00      0.00      0.00    301633\n",
      "\n",
      "    accuracy                           0.02    334600\n",
      "   macro avg       0.00      0.14      0.01    334600\n",
      "weighted avg       0.00      0.02      0.00    334600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_model(neural_network, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1342a1ac-a9fb-4818-b987-2ef9c71f180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG B-ORG\n"
     ]
    }
   ],
   "source": [
    "# По словам Владимира Наумкина, самым лучшим учебным заведением России является МФТИ.\n",
    "# O  O      B-PER     I-PER   O O     O      O       O          B-LOC  O        B-ORG O\n",
    "print(sample_model(neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5296f89-a12c-472b-a684-5252d689e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='tensorboard1/layer1_dim100_dropout0_bnormT')\n",
    "call = callback(writer, test_data, tag_to_index, token_to_index, loss_function, delimeter = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb65face-faa1-4d45-8e56-42dacef32cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2b0f1595a74a4db21f4bd2fa54eba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer(\n",
    "    num_epochs=10,\n",
    "    batch_size=64,\n",
    "    data=train_data,\n",
    "    model=neural_network,\n",
    "    tag_to_index=tag_to_index,\n",
    "    token_to_index=token_to_index,\n",
    "    loss_fn=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    callback=call\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d80acc-1f4a-4de0-9a1c-9982360c0d19",
   "metadata": {},
   "source": [
    "Качество после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6268e987-391e-4c70-9be5-a184097e4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.94      0.96      0.95      7776\n",
      "       B-ORG       0.91      0.86      0.89      7388\n",
      "       B-PER       0.97      0.92      0.94      6396\n",
      "       I-LOC       0.91      0.89      0.90      1254\n",
      "       I-ORG       0.87      0.88      0.87      5813\n",
      "       I-PER       0.96      0.98      0.97      4340\n",
      "           O       0.99      1.00      0.99    301633\n",
      "\n",
      "    accuracy                           0.99    334600\n",
      "   macro avg       0.94      0.93      0.93    334600\n",
      "weighted avg       0.99      0.99      0.99    334600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_model(neural_network, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d783f9ed-0546-4f3f-877d-73742791dcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O B-PER I-PER O O O O O B-LOC O B-ORG O\n"
     ]
    }
   ],
   "source": [
    "# По словам Владимира Наумкина, самым лучшим учебным заведением России является МФТИ.\n",
    "# O  O      B-PER     I-PER   O O     O      O       O          B-LOC  O        B-ORG O\n",
    "print(sample_model(neural_network))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab337b-b6f3-444f-89bb-4fa7f9fdff4a",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7b518-4e80-40c2-a965-ab88204f00be",
   "metadata": {},
   "source": [
    "Модель почти сразу начала правильно определять именованные сущности в моём предложении. Возможно, оно оказалось достаточно коротким и простым. Если же смотреть на classification report и графики loss, то можно сказать, что модель постепенно улучшалась и как раз начала выходить на свой максимум качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5e6ea-8f02-4007-bc64-bbb87963869d",
   "metadata": {},
   "source": [
    "Для полноты картины выведем примеры работы на тестовых предложениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "773ba33b-1a8e-431b-8575-2b4ed7158231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['«', 'Президента', '»', 'Унгер', 'и', 'еще', '26', 'человек', 'задержали', 'в', 'апреле', '2017', 'года', 'в', 'результате', 'полицейских', 'рейдов', 'по', 'всей', 'стране', '.']\n",
      "['O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "O B-ORG O B-PER O O O O O O O O O O O O O O O O O\n",
      "\n",
      "\n",
      "['Как', 'отмечают', 'эксперты', ',', 'опасности', 'для', 'банка', 'подобная', 'утечка', 'не', 'представляет', ',', 'но', 'сотрудники', 'могут', 'стать', 'мишенями', 'для', 'массовой', 'рассылки', 'фишинговых', 'писем', ',', 'рекламы', 'и', 'спама', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "\n",
      "\n",
      "['По', 'данным', 'ЦИК', ',', 'за', 'нее', 'проголосовали', '59,56', 'процентов', 'граждан', 'Грузии', '.']\n",
      "['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "\n",
      "O O B-ORG O O O O O O O B-LOC O\n",
      "\n",
      "\n",
      "['Фотография', 'быстро', 'разошлась', 'по', 'соцсетям', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "O O O O O O\n",
      "\n",
      "\n",
      "['Я', 'красивая', '.']\n",
      "['O', 'O', 'O']\n",
      "\n",
      "O O O\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    tok4check = test_data[0][i]\n",
    "    tag4check = test_data[1][i]\n",
    "    print(tok4check)\n",
    "    print(tag4check)\n",
    "    print()\n",
    "    print(sample_model(neural_network, tok4check))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e697febb-072c-4973-9710-f9b96bbc08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentence = 'В солнечный день в парке имени Пушкина в центре Москвы, где гуляли дети из школы номер 12, встречались друзья Анна, Дмитрий и Екатерина, обсуждая последние новости из жизни своих любимых артистов, таких как Сергей Безруков и Анастасия Заворотнюк, а также планы на выходные, которые они собирались провести в театре имени Маяковского, наслаждаясь спектаклем по пьесе Чехова, после чего собирались отправиться на экскурсию в музей современного искусства \"Арт-Гармония\" в Санкт-Петербурге и посетить выставку, организованную Международной ассоциацией художников \"Творчество без границ\".'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50b385b0-9041-4b91-b619-a3c0082cf7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b3bea0c-dc4d-4f01-b783-e1fb13492823",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_toks = RegexpTokenizer('[а-яА-Я]+|[^\\w\\s]|\\d+').tokenize(final_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3f17140-e8ad-44a3-add0-2d2aaef273d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_sample_model(model, sentence):\n",
    "    token_indices = [token_to_index.get(token, token_to_index['[UNK]']) for token in sentence]\n",
    "    input_tensor = torch.tensor(token_indices, dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    predicted_indices = output.argmax(dim=2).squeeze().cpu().numpy()\n",
    "    predicted_tags = [index_to_tag[index] for index in predicted_indices]\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79314e48-3a28-4848-b795-947e8465f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tags = final_sample_model(neural_network, final_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0366d350-38cd-4115-ab6b-50d23547c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В O\n",
      "солнечный O\n",
      "день O\n",
      "в O\n",
      "парке O\n",
      "имени O\n",
      "Пушкина O\n",
      "в O\n",
      "центре O\n",
      "Москвы B-LOC\n",
      ", O\n",
      "где O\n",
      "гуляли O\n",
      "дети O\n",
      "из O\n",
      "школы O\n",
      "номер O\n",
      "12 O\n",
      ", O\n",
      "встречались O\n",
      "друзья O\n",
      "Анна B-PER\n",
      ", O\n",
      "Дмитрий B-PER\n",
      "и O\n",
      "Екатерина B-PER\n",
      ", O\n",
      "обсуждая O\n",
      "последние O\n",
      "новости O\n",
      "из O\n",
      "жизни O\n",
      "своих O\n",
      "любимых O\n",
      "артистов O\n",
      ", O\n",
      "таких O\n",
      "как O\n",
      "Сергей B-PER\n",
      "Безруков I-PER\n",
      "и O\n",
      "Анастасия B-PER\n",
      "Заворотнюк I-PER\n",
      ", O\n",
      "а O\n",
      "также O\n",
      "планы O\n",
      "на O\n",
      "выходные O\n",
      ", O\n",
      "которые O\n",
      "они O\n",
      "собирались O\n",
      "провести O\n",
      "в O\n",
      "театре O\n",
      "имени O\n",
      "Маяковского O\n",
      ", O\n",
      "наслаждаясь O\n",
      "спектаклем O\n",
      "по O\n",
      "пьесе O\n",
      "Чехова B-PER\n",
      ", O\n",
      "после O\n",
      "чего O\n",
      "собирались O\n",
      "отправиться O\n",
      "на O\n",
      "экскурсию O\n",
      "в O\n",
      "музей O\n",
      "современного O\n",
      "искусства O\n",
      "\" O\n",
      "Арт O\n",
      "- O\n",
      "Гармония B-ORG\n",
      "\" O\n",
      "в O\n",
      "Санкт B-LOC\n",
      "- O\n",
      "Петербурге B-LOC\n",
      "и O\n",
      "посетить O\n",
      "выставку O\n",
      ", O\n",
      "организованную O\n",
      "Международной B-ORG\n",
      "ассоциацией I-ORG\n",
      "художников I-ORG\n",
      "\" I-ORG\n",
      "Творчество I-ORG\n",
      "без O\n",
      "границ O\n",
      "\" O\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(final_toks)):\n",
    "    print(final_toks[i], final_tags[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685724a4-8ffc-41b2-accf-fa71d49913ca",
   "metadata": {},
   "source": [
    "Даже со сгенерированным ГПТишкой предложением модель, по моему мнению, в целом отлично справилась, хотя жанр предложения - это скорее проза, а не новость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b64de0-3d85-494c-8ba2-537f914cb9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
